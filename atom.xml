<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>好运来了</title>
  
  <subtitle>分享知识、记录点滴</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://haoyunlaile.github.io/"/>
  <updated>2020-04-26T16:00:00.000Z</updated>
  <id>http://haoyunlaile.github.io/</id>
  
  <author>
    <name>好运来了</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>istio gateway</title>
    <link href="http://haoyunlaile.github.io/2020/istio/istio-gateway/"/>
    <id>http://haoyunlaile.github.io/2020/istio/istio-gateway/</id>
    <published>2020-04-26T16:00:00.000Z</published>
    <updated>2020-04-26T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Istio-Ingress-gateway-网关"><a href="#Istio-Ingress-gateway-网关" class="headerlink" title="Istio  Ingress gateway 网关"></a>Istio  Ingress gateway 网关</h2><p><img data-src="/images/istio-gateways.svg" alt="istio-gateways"></p><p>​                                                                    <em>Istio 服务网格中的网关</em> </p><p>使用网关为网格来管理入站和出站流量，可以让用户指定要进入或离开网格的流量。</p><p>网关配置被用于运行在网格内独立 Envoy 代理中，而不是服务工作负载的应用 Sidecar 代理。</p><p> <a href="https://preliminary.istio.io/zh/docs/reference/config/networking/gateway/" target="_blank" rel="noopener"><code>Gateway</code></a> 用于为 HTTP / TCP 流量配置负载均衡器，并不管该负载均衡器将在哪里运行。网格中可以存在任意数量的 <a href="https://preliminary.istio.io/zh/docs/reference/config/networking/gateway/" target="_blank" rel="noopener"><code>Gateway</code></a>，并且多个不同的 <a href="https://preliminary.istio.io/zh/docs/reference/config/networking/gateway/" target="_blank" rel="noopener"><code>Gateway</code></a> 实现可以共存。实际上，通过在配置中指定一组工作负载（Pod）标签，可以将 Gateway 配置绑定到特定的工作负载，从而允许用户通过编写简单的 Gateway Controller 来重用现成的网络设备。</p><p><code>Gateway</code> 只用于配置 L4-L6 功能（例如，对外公开的端口，TLS 配置），所有主流的 L7 代理均以统一的方式实现了这些功能。然后，通过在 <code>Gateway</code> 上绑定 <code>VirtualService</code> 的方式，可以使用标准的 Istio 规则来控制进入 <code>Gateway</code> 的 HTTP 和 TCP 流量。 </p><p>例如，下面这个简单的 <code>Gateway</code> 配置了一个 Load Balancer，以允许访问 host <code>bookinfo.com</code> 的 https 外部流量进入网格中： </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Gateway</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo-gateway</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">app:</span> <span class="string">my-ingress-gateway</span></span><br><span class="line">  <span class="attr">servers:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span></span><br><span class="line">      <span class="attr">number:</span> <span class="number">443</span></span><br><span class="line">      <span class="attr">name:</span> <span class="string">https</span></span><br><span class="line">      <span class="attr">protocol:</span> <span class="string">HTTPS</span></span><br><span class="line">    <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">bookinfo.com</span></span><br><span class="line">    <span class="attr">tls:</span></span><br><span class="line">      <span class="attr">mode:</span> <span class="string">SIMPLE</span></span><br><span class="line">      <span class="attr">serverCertificate:</span> <span class="string">/tmp/tls.crt</span></span><br><span class="line">      <span class="attr">privateKey:</span> <span class="string">/tmp/tls.key</span></span><br></pre></td></tr></table></figure><p> 要为进入上面的 Gateway 的流量配置相应的路由，必须为同一个 host 定义一个 <code>VirtualService</code>（在下一节中描述），并使用配置中的 <code>gateways</code> 字段绑定到前面定义的 <code>Gateway</code> 上： </p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">networking.istio.io/v1alpha3</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">VirtualService</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">bookinfo</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">bookinfo.com</span></span><br><span class="line">  <span class="attr">gateways:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="string">bookinfo-gateway</span> <span class="comment"># &lt;---- bind to gateway</span></span><br><span class="line">    <span class="attr">http:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">match:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">uri:</span></span><br><span class="line">        <span class="attr">prefix:</span> <span class="string">/reviews</span></span><br><span class="line">    <span class="attr">route:</span></span><br><span class="line">    <span class="string">...</span></span><br></pre></td></tr></table></figure><p>然后就可以为出口流量配置带有路由规则的虚拟服务。 </p><a id="more"></a> <h3 id="Gateway-配置信息"><a href="#Gateway-配置信息" class="headerlink" title="Gateway 配置信息"></a><code>Gateway</code> 配置信息</h3><table><thead><tr><th>ield</th><th>Type</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td>servers</td><td>Server[]</td><td>A list of server specifications.</td><td>Yes</td></tr><tr><td>selector</td><td>map</td><td>One or more labels that indicate a specific set of pods/VMs on which this gateway configuration should be applied. The scope of label search is restricted to the configuration namespace in which the the resource is present. In other words, the Gateway resource must reside in the same namespace as the gateway workload instance.</td><td>Yes</td></tr></tbody></table><h3 id="Server-配置信息"><a href="#Server-配置信息" class="headerlink" title="Server 配置信息"></a><code>Server</code> 配置信息</h3><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><code>port</code></td><td><code>Port</code></td><td>The Port on which the proxy should listen for incoming connections.</td><td>Yes</td></tr><tr><td><code>hosts</code></td><td><code>string[]</code></td><td>One or more hosts exposed by this gateway. While typically applicable to HTTP services, it can also be used for TCP services using TLS with SNI. A host is specified as a <code>dnsName</code> with an optional <code>namespace/</code> prefix. The <code>dnsName</code> should be specified using FQDN format, optionally including a wildcard character in the left-most component (e.g., <code>prod/*.example.com</code>). Set the <code>dnsName</code> to <code>*</code> to select all <code>VirtualService</code> hosts from the specified namespace (e.g.,<code>prod/*</code>).The <code>namespace</code> can be set to <code>*</code> or <code>.</code>, representing any or the current namespace, respectively. For example, <code>*/foo.example.com</code> selects the service from any available namespace while <code>./foo.example.com</code> only selects the service from the namespace of the sidecar. The default, if no <code>namespace/</code> is specified, is <code>*/</code>, that is, select services from any namespace. Any associated <code>DestinationRule</code> in the selected namespace will also be used.A <code>VirtualService</code> must be bound to the gateway and must have one or more hosts that match the hosts specified in a server. The match could be an exact match or a suffix match with the server’s hosts. For example, if the server’s hosts specifies <code>*.example.com</code>, a <code>VirtualService</code> with hosts <code>dev.example.com</code> or <code>prod.example.com</code> will match. However, a <code>VirtualService</code> with host <code>example.com</code> or <code>newexample.com</code> will not match.NOTE: Only virtual services exported to the gateway’s namespace (e.g., <code>exportTo</code> value of <code>*</code>) can be referenced. Private configurations (e.g., <code>exportTo</code> set to <code>.</code>) will not be available. Refer to the <code>exportTo</code> setting in <code>VirtualService</code>, <code>DestinationRule</code>, and <code>ServiceEntry</code> configurations for details.</td><td>Yes</td></tr><tr><td><code>tls</code></td><td><code>TLSOptions</code></td><td>Set of TLS related options that govern the server’s behavior. Use these options to control if all http requests should be redirected to https, and the TLS modes to use.</td><td>No</td></tr><tr><td><code>defaultEndpoint</code></td><td><code>string</code></td><td>The loopback IP endpoint or Unix domain socket to which traffic should be forwarded to by default. Format should be <code>127.0.0.1:PORT</code> or <code>unix:///path/to/socket</code> or <code>unix://@foobar</code> (Linux abstract namespace).</td><td>No</td></tr></tbody></table><h3 id="Port-配置信息"><a href="#Port-配置信息" class="headerlink" title="Port 配置信息"></a><code>Port</code> 配置信息</h3><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><code>number</code></td><td><code>uint32</code></td><td>A valid non-negative integer port number.</td><td>Yes</td></tr><tr><td><code>protocol</code></td><td><code>string</code></td><td>The protocol exposed on the port. MUST BE one of HTTP|HTTPS|GRPC|HTTP2|MONGO|TCP|TLS. TLS implies the connection will be routed based on the SNI header to the destination without terminating the TLS connection.</td><td>Yes</td></tr><tr><td><code>name</code></td><td><code>string</code></td><td>Label assigned to the port.</td><td>No</td></tr></tbody></table><h3 id="Server-TLSOptions-配置信息"><a href="#Server-TLSOptions-配置信息" class="headerlink" title="Server.TLSOptions 配置信息"></a><code>Server.TLSOptions</code> 配置信息</h3><table><thead><tr><th>Field</th><th>Type</th><th>Description</th><th>Required</th></tr></thead><tbody><tr><td><code>httpsRedirect</code></td><td><code>bool</code></td><td>If set to true, the load balancer will send a 301 redirect for all http connections, asking the clients to use HTTPS.</td><td>No</td></tr><tr><td><code>mode</code></td><td><code>TLSmode</code></td><td>Optional: Indicates whether connections to this port should be secured using TLS. The value of this field determines how TLS is enforced.</td><td>No</td></tr><tr><td><code>serverCertificate</code></td><td><code>string</code></td><td>REQUIRED if mode is <code>SIMPLE</code> or <code>MUTUAL</code>. The path to the file holding the server-side TLS certificate to use.</td><td>No</td></tr><tr><td><code>privateKey</code></td><td><code>string</code></td><td>REQUIRED if mode is <code>SIMPLE</code> or <code>MUTUAL</code>. The path to the file holding the server’s private key.</td><td>No</td></tr><tr><td><code>caCertificates</code></td><td><code>string</code></td><td>REQUIRED if mode is <code>MUTUAL</code>. The path to a file containing certificate authority certificates to use in verifying a presented client side certificate.</td><td>No</td></tr><tr><td><code>credentialName</code></td><td><code>string</code></td><td>The credentialName stands for a unique identifier that can be used to identify the serverCertificate and the privateKey. The credentialName appended with suffix “-cacert” is used to identify the CaCertificates associated with this server. Gateway workloads capable of fetching credentials from a remote credential store such as Kubernetes secrets, will be configured to retrieve the serverCertificate and the privateKey using credentialName, instead of using the file system paths specified above. If using mutual TLS, gateway workload instances will retrieve the CaCertificates using credentialName-cacert. The semantics of the name are platform dependent. In Kubernetes, the default Istio supplied credential server expects the credentialName to match the name of the Kubernetes secret that holds the server certificate, the private key, and the CA certificate (if using mutual TLS). Set the <code>ISTIO_META_USER_SDS</code> metadata variable in the gateway’s proxy to enable the dynamic credential fetching feature.</td><td>No</td></tr><tr><td><code>subjectAltNames</code></td><td><code>string[]</code></td><td>A list of alternate names to verify the subject identity in the certificate presented by the client.</td><td>No</td></tr><tr><td><code>verifyCertificateSpki</code></td><td><code>string[]</code></td><td>An optional list of base64-encoded SHA-256 hashes of the SKPIs of authorized client certificates. Note: When both verify<em>certificate</em>hash and verify<em>certificate</em>spki are specified, a hash matching either value will result in the certificate being accepted.</td><td>No</td></tr><tr><td><code>verifyCertificateHash</code></td><td><code>string[]</code></td><td>An optional list of hex-encoded SHA-256 hashes of the authorized client certificates. Both simple and colon separated formats are acceptable. Note: When both verify<em>certificate</em>hash and verify<em>certificate</em>spki are specified, a hash matching either value will result in the certificate being accepted.</td><td>No</td></tr><tr><td><code>minProtocolVersion</code></td><td><code>TLSProtocol</code></td><td>Optional: Minimum TLS protocol version.</td><td>No</td></tr><tr><td><code>maxProtocolVersion</code></td><td><code>TLSProtocol</code></td><td>Optional: Maximum TLS protocol version.</td><td>No</td></tr><tr><td><code>cipherSuites</code></td><td><code>string[]</code></td><td>Optional: If specified, only support the specified cipher list. Otherwise default to the default cipher list supported by Envoy.</td><td>No</td></tr></tbody></table><h3 id="Server-TLSOptions-TLSmode-配置信息"><a href="#Server-TLSOptions-TLSmode-配置信息" class="headerlink" title="Server.TLSOptions.TLSmode 配置信息"></a><code>Server.TLSOptions.TLSmode</code> 配置信息</h3><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>PASSTHROUGH</code></td><td>The SNI string presented by the client will be used as the match criterion in a VirtualService TLS route to determine the destination service from the service registry.</td></tr><tr><td><code>SIMPLE</code></td><td>Secure connections with standard TLS semantics.</td></tr><tr><td><code>MUTUAL</code></td><td>Secure connections to the downstream using mutual TLS by presenting server certificates for authentication.</td></tr><tr><td><code>AUTO_PASSTHROUGH</code></td><td>Similar to the passthrough mode, except servers with this TLS mode do not require an associated VirtualService to map from the SNI value to service in the registry. The destination details such as the service/subset/port are encoded in the SNI value. The proxy will forward to the upstream (Envoy) cluster (a group of endpoints) specified by the SNI value. This server is typically used to provide connectivity between services in disparate L3 networks that otherwise do not have direct connectivity between their respective endpoints. Use of this mode assumes that both the source and the destination are using Istio mTLS to secure traffic.</td></tr><tr><td><code>ISTIO_MUTUAL</code></td><td>Secure connections from the downstream using mutual TLS by presenting server certificates for authentication. Compared to Mutual mode, this mode uses certificates, representing gateway workload identity, generated automatically by Istio for mTLS authentication. When this mode is used, all other fields in <code>TLSOptions</code> should be empty.</td></tr></tbody></table><h3 id="Server-TLSOptions-TLSProtocol-配置信息"><a href="#Server-TLSOptions-TLSProtocol-配置信息" class="headerlink" title="Server.TLSOptions.TLSProtocol 配置信息"></a><code>Server.TLSOptions.TLSProtocol</code> 配置信息</h3><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>TLS_AUTO</code></td><td>Automatically choose the optimal TLS version.</td></tr><tr><td><code>TLSV1_0</code></td><td>TLS version 1.0</td></tr><tr><td><code>TLSV1_1</code></td><td>TLS version 1.1</td></tr><tr><td><code>TLSV1_2</code></td><td>TLS version 1.2</td></tr><tr><td><code>TLSV1_3</code></td><td>TLS version 1.3</td></tr></tbody></table><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p> <a href="https://preliminary.istio.io/zh/docs/concepts/traffic-management/#gateways" target="_blank" rel="noopener">https://preliminary.istio.io/zh/docs/concepts/traffic-management/#gateways</a> </p><p> <a href="https://preliminary.istio.io/zh//blog/2018/v1alpha3-routing/" target="_blank" rel="noopener">https://preliminary.istio.io/zh//blog/2018/v1alpha3-routing/</a></p><p> <a href="https://preliminary.istio.io/zh/docs/reference/config/networking/gateway/#Gateway" target="_blank" rel="noopener">https://preliminary.istio.io/zh/docs/reference/config/networking/gateway/#Gateway</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Istio-Ingress-gateway-网关&quot;&gt;&lt;a href=&quot;#Istio-Ingress-gateway-网关&quot; class=&quot;headerlink&quot; title=&quot;Istio  Ingress gateway 网关&quot;&gt;&lt;/a&gt;Istio  Ingress gateway 网关&lt;/h2&gt;&lt;p&gt;&lt;img data-src=&quot;/images/istio-gateways.svg&quot; alt=&quot;istio-gateways&quot;&gt;&lt;/p&gt;
&lt;p&gt;​                                                                    &lt;em&gt;Istio 服务网格中的网关&lt;/em&gt; &lt;/p&gt;
&lt;p&gt;使用网关为网格来管理入站和出站流量，可以让用户指定要进入或离开网格的流量。&lt;/p&gt;
&lt;p&gt;网关配置被用于运行在网格内独立 Envoy 代理中，而不是服务工作负载的应用 Sidecar 代理。&lt;/p&gt;
&lt;p&gt; &lt;a href=&quot;https://preliminary.istio.io/zh/docs/reference/config/networking/gateway/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;Gateway&lt;/code&gt;&lt;/a&gt; 用于为 HTTP / TCP 流量配置负载均衡器，并不管该负载均衡器将在哪里运行。网格中可以存在任意数量的 &lt;a href=&quot;https://preliminary.istio.io/zh/docs/reference/config/networking/gateway/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;Gateway&lt;/code&gt;&lt;/a&gt;，并且多个不同的 &lt;a href=&quot;https://preliminary.istio.io/zh/docs/reference/config/networking/gateway/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;code&gt;Gateway&lt;/code&gt;&lt;/a&gt; 实现可以共存。实际上，通过在配置中指定一组工作负载（Pod）标签，可以将 Gateway 配置绑定到特定的工作负载，从而允许用户通过编写简单的 Gateway Controller 来重用现成的网络设备。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gateway&lt;/code&gt; 只用于配置 L4-L6 功能（例如，对外公开的端口，TLS 配置），所有主流的 L7 代理均以统一的方式实现了这些功能。然后，通过在 &lt;code&gt;Gateway&lt;/code&gt; 上绑定 &lt;code&gt;VirtualService&lt;/code&gt; 的方式，可以使用标准的 Istio 规则来控制进入 &lt;code&gt;Gateway&lt;/code&gt; 的 HTTP 和 TCP 流量。 &lt;/p&gt;
&lt;p&gt;例如，下面这个简单的 &lt;code&gt;Gateway&lt;/code&gt; 配置了一个 Load Balancer，以允许访问 host &lt;code&gt;bookinfo.com&lt;/code&gt; 的 https 外部流量进入网格中： &lt;/p&gt;
&lt;figure class=&quot;highlight yaml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;apiVersion:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;kind:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;Gateway&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;metadata:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;attr&quot;&gt;name:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;bookinfo-gateway&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;spec:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;attr&quot;&gt;selector:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attr&quot;&gt;app:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;my-ingress-gateway&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;attr&quot;&gt;servers:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;bullet&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;port:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;attr&quot;&gt;number:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;443&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;attr&quot;&gt;name:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;https&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;attr&quot;&gt;protocol:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;HTTPS&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attr&quot;&gt;hosts:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;bullet&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;bookinfo.com&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attr&quot;&gt;tls:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;attr&quot;&gt;mode:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;SIMPLE&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;attr&quot;&gt;serverCertificate:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;/tmp/tls.crt&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      &lt;span class=&quot;attr&quot;&gt;privateKey:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;/tmp/tls.key&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt; 要为进入上面的 Gateway 的流量配置相应的路由，必须为同一个 host 定义一个 &lt;code&gt;VirtualService&lt;/code&gt;（在下一节中描述），并使用配置中的 &lt;code&gt;gateways&lt;/code&gt; 字段绑定到前面定义的 &lt;code&gt;Gateway&lt;/code&gt; 上： &lt;/p&gt;
&lt;figure class=&quot;highlight yaml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;apiVersion:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;kind:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;VirtualService&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;metadata:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;attr&quot;&gt;name:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;bookinfo&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attr&quot;&gt;spec:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;attr&quot;&gt;hosts:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;bullet&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;bookinfo.com&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;attr&quot;&gt;gateways:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;bullet&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;bookinfo-gateway&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;# &amp;lt;---- bind to gateway&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attr&quot;&gt;http:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  &lt;span class=&quot;bullet&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;match:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;bullet&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;attr&quot;&gt;uri:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;        &lt;span class=&quot;attr&quot;&gt;prefix:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;/reviews&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attr&quot;&gt;route:&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;string&quot;&gt;...&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;然后就可以为出口流量配置带有路由规则的虚拟服务。 &lt;/p&gt;
    
    </summary>
    
    
      <category term="istio" scheme="http://haoyunlaile.github.io/categories/istio/"/>
    
    
      <category term="istio" scheme="http://haoyunlaile.github.io/tags/istio/"/>
    
      <category term="istio gateway" scheme="http://haoyunlaile.github.io/tags/istio-gateway/"/>
    
  </entry>
  
  <entry>
    <title>istio使用的端口</title>
    <link href="http://haoyunlaile.github.io/2020/istio/istio-port/"/>
    <id>http://haoyunlaile.github.io/2020/istio/istio-port/</id>
    <published>2020-04-24T16:00:00.000Z</published>
    <updated>2020-04-24T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Istio-使用了如下的端口和协议"><a href="#Istio-使用了如下的端口和协议" class="headerlink" title="Istio 使用了如下的端口和协议"></a>Istio 使用了如下的端口和协议</h2><table><thead><tr><th>端口</th><th>协议</th><th align="left">使用者</th><th>描述</th></tr></thead><tbody><tr><td>8060</td><td>HTTP</td><td align="left">Citadel</td><td>GRPC 服务器</td></tr><tr><td>8080</td><td>HTTP</td><td align="left">Citadel agent</td><td>SDS service 监控</td></tr><tr><td>9090</td><td>HTTP</td><td align="left">Prometheus</td><td>Prometheus</td></tr><tr><td>9091</td><td>HTTP</td><td align="left">Mixer</td><td>策略/遥测</td></tr><tr><td>9876</td><td>HTTP</td><td align="left">Citadel, Citadel agent</td><td>ControlZ 用户界面</td></tr><tr><td>9901</td><td>GRPC</td><td align="left">Galley</td><td>网格配置协议</td></tr><tr><td>15000</td><td>TCP</td><td align="left">Envoy</td><td>Envoy 管理端口 (commands/diagnostics)</td></tr><tr><td>15001</td><td>TCP</td><td align="left">Envoy</td><td>Envoy 传出</td></tr><tr><td>15006</td><td>TCP</td><td align="left">Envoy</td><td>Envoy 传入</td></tr><tr><td>15004</td><td>HTTP</td><td align="left">Mixer, Pilot</td><td>策略/遥测 - <code>mTLS</code></td></tr><tr><td>15010</td><td>HTTP</td><td align="left">Pilot</td><td>Pilot service - XDS pilot - 发现</td></tr><tr><td>15011</td><td>TCP</td><td align="left">Pilot</td><td>Pilot service - <code>mTLS</code> - Proxy - 发现</td></tr><tr><td>15014</td><td>HTTP</td><td align="left">Citadel, Citadel agent, Galley, Mixer, Pilot, Sidecar Injector</td><td>控制平面监控</td></tr><tr><td>15020</td><td>HTTP</td><td align="left">Ingress Gateway</td><td>Pilot 健康检查</td></tr><tr><td>15029</td><td>HTTP</td><td align="left">Kiali</td><td>Kiali 用户界面</td></tr><tr><td>15030</td><td>HTTP</td><td align="left">Prometheus</td><td>Prometheus 用户界面</td></tr><tr><td>15031</td><td>HTTP</td><td align="left">Grafana</td><td>Grafana 用户界面</td></tr><tr><td>15032</td><td>HTTP</td><td align="left">Tracing</td><td>Tracing 用户界面</td></tr><tr><td>15443</td><td>TLS</td><td align="left">Ingress and Egress Gateways</td><td>SNI</td></tr><tr><td>15090</td><td>HTTP</td><td align="left">Mixer</td><td>Proxy</td></tr><tr><td>42422</td><td>TCP</td><td align="left">Mixer</td><td>遥测 - Prometheus</td></tr></tbody></table><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p> <a href="https://preliminary.istio.io/docs/ops/deployment/requirements/" target="_blank" rel="noopener">https://preliminary.istio.io/docs/ops/deployment/requirements/</a> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Istio-使用了如下的端口和协议&quot;&gt;&lt;a href=&quot;#Istio-使用了如下的端口和协议&quot; class=&quot;headerlink&quot; title=&quot;Istio 使用了如下的端口和协议&quot;&gt;&lt;/a&gt;Istio 使用了如下的端口和协议&lt;/h2&gt;&lt;table&gt;
&lt;thea
      
    
    </summary>
    
    
      <category term="istio" scheme="http://haoyunlaile.github.io/categories/istio/"/>
    
    
      <category term="istio" scheme="http://haoyunlaile.github.io/tags/istio/"/>
    
  </entry>
  
  <entry>
    <title>istio 1.6架构及性能</title>
    <link href="http://haoyunlaile.github.io/2020/istio/istio-architecture-performance/"/>
    <id>http://haoyunlaile.github.io/2020/istio/istio-architecture-performance/</id>
    <published>2020-04-24T16:00:00.000Z</published>
    <updated>2020-04-24T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Istio-架构"><a href="#Istio-架构" class="headerlink" title="Istio 架构"></a>Istio 架构</h2><p> Istio 服务网格从逻辑上分为数据平面和控制平面。</p><ul><li><strong>数据平面</strong> 由一组智能代理（<a href="https://www.envoyproxy.io/" target="_blank" rel="noopener">Envoy</a>）组成，被部署为 sidecar。这些代理负责协调和控制微服务之间的所有网络通信。他们还收集和报告所有网格流量的遥测数据。</li><li><strong>控制平面</strong> 管理并配置代理来进行流量路由。</li></ul><h2 id="Istio-核心组件"><a href="#Istio-核心组件" class="headerlink" title="Istio 核心组件"></a>Istio 核心组件</h2><p>下图展示了组成每个平面的不同组件： </p><p><img data-src="/images/istio-arch.svg" alt="istio-arch"></p><p> Istio 中的流量分为数据平面流量和控制平面流量。</p><ul><li>数据平面流量是指工作负载的业务逻辑发送和接收的消息</li><li>控制平面流量是指在 Istio 组件之间发送的配置和控制消息用来编排网格的行为</li><li>Istio  中的流量管理特指数据平面流量</li></ul><a id="more"></a> <h3 id="Envoy"><a href="#Envoy" class="headerlink" title="Envoy"></a>Envoy</h3><p>Istio 使用 <a href="https://envoyproxy.github.io/envoy/" target="_blank" rel="noopener">Envoy</a> 代理的扩展版本。Envoy 是用 C++ 开发的高性能代理，用于协调服务网格中所有服务的入站和出站流量。Envoy 代理是唯一与数据平面流量交互的 Istio 组件。</p><p>Envoy 代理被部署为服务的 sidecar，在逻辑上为服务增加了 Envoy 的许多内置特性，例如:</p><ul><li><p>动态服务发现</p></li><li><p>负载均衡</p></li><li><p>TLS 终端</p></li><li><p>HTTP/2 与 gRPC 代理</p></li><li><p>熔断器</p></li><li><p>健康检查</p></li><li><p>基于百分比流量分割的分阶段发布</p></li><li><p>故障注入</p></li><li><p>丰富的指标</p><p>这种 sidecar 部署允许 Istio 提取大量关于流量行为的信号作为属性。Istio 可以使用这些属性来实施策略决策，并将其发送到监视系统以提供有关整个网格行为的信息。 </p></li></ul><p>由 Envoy 代理启用的一些 Istio 的功能和任务包括:</p><ul><li>流量控制功能：通过丰富的 HTTP、gRPC、WebSocket 和 TCP 流量路由规则来执行细粒度的流量控制。</li><li>网络弹性特性：重试设置、故障转移、熔断器和故障注入。</li><li>安全性和身份验证特性：执行安全性策略以及通过配置 API 定义的访问控制和速率限制。</li><li>基于 WebAssembly 的可插拔扩展模型，允许通过自定义策略实施和生成网格流量的遥测。</li></ul><h3 id="Pilot"><a href="#Pilot" class="headerlink" title="Pilot"></a>Pilot</h3><p><code>Pilot</code> 为 Envoy sidecar 提供服务发现、用于智能路由的流量管理功能（例如，A/B 测试、金丝雀发布等）以及弹性功能（超时、重试、熔断器等）。</p><p><code>Pilot</code> 将控制流量行为的高级路由规则转换为特定于环境的配置，并在运行时将它们传播到 sidecar。Pilot 将特定于平台的服务发现机制抽象出来，并将它们合成为任何符合 <a href="https://www.envoyproxy.io/docs/envoy/latest/api/api" target="_blank" rel="noopener">Envoy API</a> 的 sidecar 都可以使用的标准格式。</p><p>下图展示了平台适配器和 Envoy 代理如何交互。</p><p><img data-src="/images/pilot-discovery.svg" alt="pilot-discovery"></p><ol><li>平台启动一个服务的新实例，该实例通知其平台适配器。</li><li>平台适配器使用 <code>Pilot</code> 抽象模型注册实例。</li><li><code>Pilot</code> 将流量规则和配置派发给 <code>Envoy</code> 代理，来传达此次更改。</li></ol><h3 id="Citadel"><a href="#Citadel" class="headerlink" title="Citadel"></a>Citadel</h3><p><code>Citadel</code>通过内置的身份和证书管理，可以支持强大的服务到服务以及最终用户的身份验证。您可以使用 Citadel 来升级服务网格中的未加密流量。使用 <code>Citadel</code> operator 可以执行基于服务身份的策略。</p><h3 id="Galley"><a href="#Galley" class="headerlink" title="Galley"></a>Galley</h3><p><code>Galley</code> 是 Istio 的配置验证、提取、处理和分发组件。它负责将其余的 Istio 组件与从底层平台（例如 Kubernetes）获取用户配置的细节隔离开来。</p><h2 id="Istio-部署模型"><a href="#Istio-部署模型" class="headerlink" title="Istio 部署模型"></a>Istio 部署模型</h2><p>您可以将单个网格配置为包括多集群。多集群部署可为您提供更大程度的隔离和可用性，但会增加复杂性。 如果您的系统具有高可用性要求，则可能需要集群跨多个可用区和地域。 对于应用变更或新的版本，您可以在一个集群中配置金丝雀发布，这有助于把对用户的影响降到最低。 此外，如果某个集群有问题，您可以暂时将流量路由到附近的集群，直到解决该问题为止。 </p><p> <img data-src="/images/istio-multi-cluster.svg" alt="istio-multi-cluster"></p><h2 id="Istio-1-6-性能总结"><a href="#Istio-1-6-性能总结" class="headerlink" title="Istio 1.6 性能总结"></a>Istio 1.6 性能总结</h2><p><a href="https://github.com/istio/tools/tree/master/perf/load" target="_blank" rel="noopener">Istio 负载测试</a> 网格包含了 <strong>1000</strong> 个服务和 <strong>2000</strong> 个 sidecar，全网格范围内，QPS 为 70,000。 在使用 Istio 1.6 运行测试后，我们得到了如下结果：</p><ul><li>通过代理的 QPS 有 1000 时，Envoy 使用了 <strong>0.5 vCPU</strong> 和 <strong>50 MB 内存</strong>。</li><li>网格总的 QPS 为 1000 时，<code>istio-telemetry</code> 服务使用了 <strong>0.6 vCPU</strong>。</li><li>Pilot 使用了 <strong>1 vCPU</strong> 和 <strong>1.5 GB</strong> 内存。</li><li><strong>90%</strong> 的情况 Envoy 代理只增加了 <strong>2.8 ms</strong> 的延迟。</li></ul><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p> <a href="https://preliminary.istio.io/docs/ops/deployment/architecture/" target="_blank" rel="noopener">https://preliminary.istio.io/docs/ops/deployment/architecture/</a> </p><p> <a href="https://preliminary.istio.io/zh/docs/ops/deployment/architecture/" target="_blank" rel="noopener">https://preliminary.istio.io/zh/docs/ops/deployment/architecture/</a> </p><p> <a href="https://preliminary.istio.io/zh/docs/ops/deployment/deployment-models/" target="_blank" rel="noopener">https://preliminary.istio.io/zh/docs/ops/deployment/deployment-models/</a></p><p> <a href="https://preliminary.istio.io/docs/ops/deployment/performance-and-scalability/" target="_blank" rel="noopener">https://preliminary.istio.io/docs/ops/deployment/performance-and-scalability/</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Istio-架构&quot;&gt;&lt;a href=&quot;#Istio-架构&quot; class=&quot;headerlink&quot; title=&quot;Istio 架构&quot;&gt;&lt;/a&gt;Istio 架构&lt;/h2&gt;&lt;p&gt; Istio 服务网格从逻辑上分为数据平面和控制平面。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;数据平面&lt;/strong&gt; 由一组智能代理（&lt;a href=&quot;https://www.envoyproxy.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Envoy&lt;/a&gt;）组成，被部署为 sidecar。这些代理负责协调和控制微服务之间的所有网络通信。他们还收集和报告所有网格流量的遥测数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;控制平面&lt;/strong&gt; 管理并配置代理来进行流量路由。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Istio-核心组件&quot;&gt;&lt;a href=&quot;#Istio-核心组件&quot; class=&quot;headerlink&quot; title=&quot;Istio 核心组件&quot;&gt;&lt;/a&gt;Istio 核心组件&lt;/h2&gt;&lt;p&gt;下图展示了组成每个平面的不同组件： &lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;/images/istio-arch.svg&quot; alt=&quot;istio-arch&quot;&gt;&lt;/p&gt;
&lt;p&gt; Istio 中的流量分为数据平面流量和控制平面流量。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据平面流量是指工作负载的业务逻辑发送和接收的消息&lt;/li&gt;
&lt;li&gt;控制平面流量是指在 Istio 组件之间发送的配置和控制消息用来编排网格的行为&lt;/li&gt;
&lt;li&gt;Istio  中的流量管理特指数据平面流量&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="istio" scheme="http://haoyunlaile.github.io/categories/istio/"/>
    
    
      <category term="istio" scheme="http://haoyunlaile.github.io/tags/istio/"/>
    
  </entry>
  
  <entry>
    <title>istio install</title>
    <link href="http://haoyunlaile.github.io/2020/istio/istio-install/"/>
    <id>http://haoyunlaile.github.io/2020/istio/istio-install/</id>
    <published>2020-04-22T16:00:00.000Z</published>
    <updated>2020-04-22T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>搭建istio基础环境</p><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>在安装 Istio 之前，需要一个运行着 Kubernetes 的环境，安装步骤可以参考前面的文章</p><p>下载istio，然后解压，然后将 <code>istioctl</code> 增加到 path 环境变量中 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -L https://istio.io/downloadIstio | sh -</span><br><span class="line"><span class="built_in">cd</span> istio-1.5.1</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PWD</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure><p> 新建<code>istio-1.5.1.yaml</code> 配置文件、按照官方文档操作安装会出现错误，导致不能正常进行sidecar 自动注入</p><a id="more"></a> <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">vim</span> <span class="selector-tag">istio-1</span><span class="selector-class">.5</span><span class="selector-class">.1</span><span class="selector-class">.yaml</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: install.istio.io/v1alpha1</span><br><span class="line">kind: IstioOperator</span><br><span class="line">spec:</span><br><span class="line">  components:</span><br><span class="line">    egressGateways:</span><br><span class="line">    - name: istio-egressgateway</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">      k8s:</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 40Mi</span><br><span class="line"></span><br><span class="line">    ingressGateways:</span><br><span class="line">    - name: istio-ingressgateway</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">      k8s:</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 40Mi</span><br><span class="line">        service:</span><br><span class="line">          ports:</span><br><span class="line">            <span class="comment">## You can add custom gateway ports in user values overrides, but it must include those ports since helm replaces.</span></span><br><span class="line">            <span class="comment"># Note that AWS ELB will by default perform health checks on the first port</span></span><br><span class="line">            <span class="comment"># on this list. Setting this to the health check port will ensure that health</span></span><br><span class="line">            <span class="comment"># checks always work. https://github.com/istio/istio/issues/12503</span></span><br><span class="line">            - port: 15020</span><br><span class="line">              targetPort: 15020</span><br><span class="line">              name: status-port</span><br><span class="line">            - port: 80</span><br><span class="line">              targetPort: 8080</span><br><span class="line">              name: http2</span><br><span class="line">            - port: 443</span><br><span class="line">              targetPort: 8443</span><br><span class="line">              name: https</span><br><span class="line">            - port: 31400</span><br><span class="line">              targetPort: 31400</span><br><span class="line">              name: tcp</span><br><span class="line">              <span class="comment"># This is the port where sni routing happens</span></span><br><span class="line">            - port: 15443</span><br><span class="line">              targetPort: 15443</span><br><span class="line">              name: tls</span><br><span class="line"></span><br><span class="line">    policy:</span><br><span class="line">      enabled: <span class="literal">false</span></span><br><span class="line">      k8s:</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 100Mi</span><br><span class="line"></span><br><span class="line">    telemetry:</span><br><span class="line">      k8s:</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 50m</span><br><span class="line">            memory: 100Mi</span><br><span class="line"></span><br><span class="line">    pilot:</span><br><span class="line">      k8s:</span><br><span class="line">        env:</span><br><span class="line">          - name: POD_NAME</span><br><span class="line">            valueFrom:</span><br><span class="line">              fieldRef:</span><br><span class="line">                apiVersion: v1</span><br><span class="line">                fieldPath: metadata.name</span><br><span class="line">          - name: POD_NAMESPACE</span><br><span class="line">            valueFrom:</span><br><span class="line">              fieldRef:</span><br><span class="line">                apiVersion: v1</span><br><span class="line">                fieldPath: metadata.namespace</span><br><span class="line">          - name: GODEBUG</span><br><span class="line">            value: gctrace=1</span><br><span class="line">          - name: PILOT_TRACE_SAMPLING</span><br><span class="line">            value: <span class="string">"100"</span></span><br><span class="line">          - name: CONFIG_NAMESPACE</span><br><span class="line">            value: istio-config</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 100Mi</span><br><span class="line"></span><br><span class="line">  addonComponents:</span><br><span class="line">    kiali:</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">    grafana:</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">    tracing:</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line">    prometheus:</span><br><span class="line">      enabled: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">  values:</span><br><span class="line">    global:</span><br><span class="line">      disablePolicyChecks: <span class="literal">false</span></span><br><span class="line">      proxy:</span><br><span class="line">        accessLogFile: /dev/stdout</span><br><span class="line">        includeIPRanges: 192.168.16.0/20,192.168.32.0/20</span><br><span class="line">        autoInject: enabled  <span class="comment">#配置自动注入</span></span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 10m</span><br><span class="line">            memory: 40Mi</span><br><span class="line">    sidecarInjectorWebhook:</span><br><span class="line">      enableNamespacesByDefault: <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">    pilot:</span><br><span class="line">      autoscaleEnabled: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">    mixer:</span><br><span class="line">      adapters:</span><br><span class="line">        useAdapterCRDs: <span class="literal">false</span></span><br><span class="line">        kubernetesenv:</span><br><span class="line">          enabled: <span class="literal">true</span></span><br><span class="line">        prometheus:</span><br><span class="line">          enabled: <span class="literal">true</span></span><br><span class="line">          metricsExpiryDuration: 10m</span><br><span class="line">        stackdriver:</span><br><span class="line">          enabled: <span class="literal">false</span></span><br><span class="line">        stdio:</span><br><span class="line">          enabled: <span class="literal">true</span></span><br><span class="line">          outputAsJson: <span class="literal">false</span></span><br><span class="line">      policy:</span><br><span class="line">        autoscaleEnabled: <span class="literal">false</span></span><br><span class="line">      telemetry:</span><br><span class="line">        autoscaleEnabled: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">    gateways:</span><br><span class="line">      istio-egressgateway:</span><br><span class="line">        autoscaleEnabled: <span class="literal">true</span></span><br><span class="line">      istio-ingressgateway:</span><br><span class="line">        autoscaleEnabled: <span class="literal">true</span></span><br><span class="line">    kiali:</span><br><span class="line">      createDemoSecret: <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>安装对应配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">istioctl manifest apply -f istio-1.5.1.yaml</span><br></pre></td></tr></table></figure><p> 验证是否安装成功 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">kubectl get svc -n istio-system</span><br><span class="line"></span><br><span class="line">NAME                        TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                                      AGE</span><br><span class="line">grafana                     ClusterIP      10.106.222.1     &lt;none&gt;        3000/TCP                                                                     72m</span><br><span class="line">istio-egressgateway         ClusterIP      10.105.147.175   &lt;none&gt;        80/TCP,443/TCP,15443/TCP                                                     72m</span><br><span class="line">istio-ingressgateway        LoadBalancer   10.101.90.130    &lt;pending&gt;     15020:31121/TCP,80:31729/TCP,443:31903/TCP,31400:32746/TCP,15443:31084/TCP   72m</span><br><span class="line">istio-pilot                 ClusterIP      10.101.28.124    &lt;none&gt;        15010/TCP,15011/TCP,15012/TCP,8080/TCP,15014/TCP,443/TCP                     80m</span><br><span class="line">istiod                      ClusterIP      10.99.35.177     &lt;none&gt;        15012/TCP,443/TCP                                                            80m</span><br><span class="line">jaeger-agent                ClusterIP      None             &lt;none&gt;        5775/UDP,6831/UDP,6832/UDP                                                   72m</span><br><span class="line">jaeger-collector            ClusterIP      10.109.237.212   &lt;none&gt;        14267/TCP,14268/TCP,14250/TCP                                                72m</span><br><span class="line">jaeger-collector-headless   ClusterIP      None             &lt;none&gt;        14250/TCP                                                                    72m</span><br><span class="line">jaeger-query                ClusterIP      10.103.4.63      &lt;none&gt;        16686/TCP                                                                    72m</span><br><span class="line">kiali                       ClusterIP      10.100.49.221    &lt;none&gt;        20001/TCP                                                                    72m</span><br><span class="line">prometheus                  ClusterIP      10.110.124.176   &lt;none&gt;        9090/TCP                                                                     72m</span><br><span class="line">tracing                     ClusterIP      10.106.75.109    &lt;none&gt;        80/TCP                                                                       72m</span><br><span class="line">zipkin                      ClusterIP      10.103.9.94      &lt;none&gt;        9411/TCP</span><br></pre></td></tr></table></figure><p> 确保关联的 Kubernetes pod 已经部署，并且 <code>STATUS</code> 为 <code>Running</code> </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n istio-system</span><br><span class="line"></span><br><span class="line">NAME                                    READY   STATUS    RESTARTS   AGE</span><br><span class="line">grafana-5f6f8cbf75-trjl6                1/1     Running   0          73m</span><br><span class="line">istio-egressgateway-74896c8487-9qnwg    1/1     Running   0          73m</span><br><span class="line">istio-ingressgateway-56f7dd5d6b-9c22z   1/1     Running   0          73m</span><br><span class="line">istio-tracing-9dd6c4f7c-qr7vl           1/1     Running   0          73m</span><br><span class="line">istiod-756bd84654-fqp7b                 1/1     Running   0          73m</span><br><span class="line">istiod-756bd84654-hxpqt                 1/1     Running   0          73m</span><br><span class="line">kiali-869c6894c5-p4h7r                  1/1     Running   0          73m</span><br><span class="line">prometheus-c89875c74-lvq52              2/2     Running   0          73m</span><br></pre></td></tr></table></figure><p>卸载istio</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">istioctl manifest generate --<span class="built_in">set</span> profile=demo | kubectl delete -f -</span><br></pre></td></tr></table></figure><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p> <a href="https://preliminary.istio.io/zh/docs/setup/getting-started/" target="_blank" rel="noopener">https://preliminary.istio.io/zh/docs/setup/getting-started/</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h2&gt;&lt;p&gt;搭建istio基础环境&lt;/p&gt;
&lt;h2 id=&quot;安装步骤&quot;&gt;&lt;a href=&quot;#安装步骤&quot; class=&quot;headerlink&quot; title=&quot;安装步骤&quot;&gt;&lt;/a&gt;安装步骤&lt;/h2&gt;&lt;p&gt;在安装 Istio 之前，需要一个运行着 Kubernetes 的环境，安装步骤可以参考前面的文章&lt;/p&gt;
&lt;p&gt;下载istio，然后解压，然后将 &lt;code&gt;istioctl&lt;/code&gt; 增加到 path 环境变量中 &lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;curl -L https://istio.io/downloadIstio | sh -&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; istio-1.5.1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; PATH=&lt;span class=&quot;variable&quot;&gt;$PWD&lt;/span&gt;/bin:&lt;span class=&quot;variable&quot;&gt;$PATH&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt; 新建&lt;code&gt;istio-1.5.1.yaml&lt;/code&gt; 配置文件、按照官方文档操作安装会出现错误，导致不能正常进行sidecar 自动注入&lt;/p&gt;
    
    </summary>
    
    
      <category term="istio" scheme="http://haoyunlaile.github.io/categories/istio/"/>
    
    
      <category term="istio" scheme="http://haoyunlaile.github.io/tags/istio/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes资料</title>
    <link href="http://haoyunlaile.github.io/2020/kubernates/kubernates-basics/"/>
    <id>http://haoyunlaile.github.io/2020/kubernates/kubernates-basics/</id>
    <published>2020-04-22T16:00:00.000Z</published>
    <updated>2020-04-22T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>这篇文章用来记录Kubernetes 的基础资料，整体以最新官方文档为准。</p><p>因为k8s整体比较偏运维，作为研发可先大致了解其概念及初级使用方式，后面重点学习点会放在service mesh <code>istio</code> 上。因为<code>istio</code>目前的架构依赖k8s相关组件，后面在学习<code>istio</code> 的过程中使用到k8s具体组件后再回过头来针对性的学习。</p><h3 id="Kubernetes-集群所需的各种组件"><a href="#Kubernetes-集群所需的各种组件" class="headerlink" title="Kubernetes 集群所需的各种组件"></a>Kubernetes 集群所需的各种组件</h3><p><img data-src="/images/components-of-kubernetes.png" alt="components-of-kubernetes.png"></p><p>最好把官方相关文档全部都认认真真看一遍，然后跟着操作一遍会强化理解。因为涉及的体系非常庞大，里面使用到的一个组件可能都需要学习很久，不要着急，慢慢来，有计划一个一个的啃下来。术业有专攻、有目标性的学习与突破。道路且长、共勉</p><a id="more"></a> <h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://kubernetes.io/zh/docs/concepts/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/</a> </p><p><a href="https://kubernetes.io/zh/docs/concepts/overview/components/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/overview/components/</a> </p><p><a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-overview/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-overview/</a> </p><p><a href="https://kubernetes.io/zh/docs/tasks/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/tasks/</a> </p><p><a href="https://kubernetes.io/zh/docs/reference/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/</a> </p><p><a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#-strong-getting-started-strong-" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#-strong-getting-started-strong-</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;这篇文章用来记录Kubernetes 的基础资料，整体以最新官方文档为准。&lt;/p&gt;
&lt;p&gt;因为k8s整体比较偏运维，作为研发可先大致了解其概念及初级使用方式，后面重点学习点会放在service mesh &lt;code&gt;istio&lt;/code&gt; 上。因为&lt;code&gt;istio&lt;/code&gt;目前的架构依赖k8s相关组件，后面在学习&lt;code&gt;istio&lt;/code&gt; 的过程中使用到k8s具体组件后再回过头来针对性的学习。&lt;/p&gt;
&lt;h3 id=&quot;Kubernetes-集群所需的各种组件&quot;&gt;&lt;a href=&quot;#Kubernetes-集群所需的各种组件&quot; class=&quot;headerlink&quot; title=&quot;Kubernetes 集群所需的各种组件&quot;&gt;&lt;/a&gt;Kubernetes 集群所需的各种组件&lt;/h3&gt;&lt;p&gt;&lt;img data-src=&quot;/images/components-of-kubernetes.png&quot; alt=&quot;components-of-kubernetes.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;最好把官方相关文档全部都认认真真看一遍，然后跟着操作一遍会强化理解。因为涉及的体系非常庞大，里面使用到的一个组件可能都需要学习很久，不要着急，慢慢来，有计划一个一个的啃下来。术业有专攻、有目标性的学习与突破。道路且长、共勉&lt;/p&gt;
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://haoyunlaile.github.io/categories/kubernetes/"/>
    
    
      <category term="kubernetes资料" scheme="http://haoyunlaile.github.io/tags/kubernetes%E8%B5%84%E6%96%99/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes port list</title>
    <link href="http://haoyunlaile.github.io/2020/kubernates/k8s-port/"/>
    <id>http://haoyunlaile.github.io/2020/kubernates/k8s-port/</id>
    <published>2020-04-21T16:00:00.000Z</published>
    <updated>2020-04-21T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="搭建k8s环境所需端口清单"><a href="#搭建k8s环境所需端口清单" class="headerlink" title="搭建k8s环境所需端口清单"></a>搭建k8s环境所需端口清单</h2><h3 id="控制平面节点端口清单"><a href="#控制平面节点端口清单" class="headerlink" title="控制平面节点端口清单"></a>控制平面节点端口清单</h3><table><thead><tr><th align="center">协议</th><th align="center">方向</th><th align="center">端口范围</th><th align="center">作用</th><th align="center">使用者</th></tr></thead><tbody><tr><td align="center">TCP</td><td align="center">入站</td><td align="center">6443</td><td align="center">Kubernetes API 服务器</td><td align="center">所有组件</td></tr><tr><td align="center">TCP</td><td align="center">入站</td><td align="center">2379-2380</td><td align="center">etcd server client API</td><td align="center">kube-apiserver, etcd</td></tr><tr><td align="center">TCP</td><td align="center">入站</td><td align="center">10250</td><td align="center">Kubelet API</td><td align="center">kubelet 自身、控制平面组件</td></tr><tr><td align="center">TCP</td><td align="center">入站</td><td align="center">10251</td><td align="center">kube-scheduler</td><td align="center">kube-scheduler 自身</td></tr><tr><td align="center">TCP</td><td align="center">入站</td><td align="center">10252</td><td align="center">kube-controller-manager</td><td align="center">kube-controller-manager 自身</td></tr></tbody></table><h3 id="Node节点端口清单"><a href="#Node节点端口清单" class="headerlink" title="Node节点端口清单"></a>Node节点端口清单</h3><table><thead><tr><th align="center">协议</th><th align="center">方向</th><th align="center">端口范围</th><th align="center">作用</th><th align="center">使用者</th></tr></thead><tbody><tr><td align="center">TCP</td><td align="center">入站</td><td align="center">10250</td><td align="center">Kubelet API</td><td align="center">kubelet 自身、控制平面组件</td></tr><tr><td align="center">TCP</td><td align="center">入站</td><td align="center">30000-32767</td><td align="center">NodePort 服务**</td><td align="center">所有组件</td></tr></tbody></table><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p> <a href="https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/</a> </p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;搭建k8s环境所需端口清单&quot;&gt;&lt;a href=&quot;#搭建k8s环境所需端口清单&quot; class=&quot;headerlink&quot; title=&quot;搭建k8s环境所需端口清单&quot;&gt;&lt;/a&gt;搭建k8s环境所需端口清单&lt;/h2&gt;&lt;h3 id=&quot;控制平面节点端口清单&quot;&gt;&lt;a href=&quot;
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://haoyunlaile.github.io/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="http://haoyunlaile.github.io/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>kubeadm built kubernetes cluster</title>
    <link href="http://haoyunlaile.github.io/2020/kubernates/kubeadm-install/"/>
    <id>http://haoyunlaile.github.io/2020/kubernates/kubeadm-install/</id>
    <published>2020-04-21T16:00:00.000Z</published>
    <updated>2020-04-21T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>kubeadm 搭建kubernetes集群环境</p><h2 id="准备条件"><a href="#准备条件" class="headerlink" title="准备条件"></a>准备条件</h2><ol><li>三台VPS（本文使用<strong>阿里云香港</strong> - centos7.7）- 用国内的服务器折腾的好一会儿都被墙了，先不把时间浪费在这，直接上香港的服务器</li><li>一台能SSH连接到VPS的本地电脑 （推荐连接工具xshell）</li></ol><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>在安装前需要配置国内的镜像源，这里推荐使用阿里云的</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; <span class="regexp">/etc/yum</span>.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=<span class="symbol">https:</span>/<span class="regexp">/mirrors.aliyun.com/kubernetes</span><span class="regexp">/yum/repos</span><span class="regexp">/kubernetes-el7-x86_64/</span></span><br><span class="line">enabled=<span class="number">1</span></span><br><span class="line">gpgcheck=<span class="number">1</span></span><br><span class="line">repo_gpgcheck=<span class="number">1</span></span><br><span class="line">gpgkey=<span class="symbol">https:</span>/<span class="regexp">/mirrors.aliyun.com/kubernetes</span><span class="regexp">/yum/doc</span><span class="regexp">/yum-key.gpg https:/</span><span class="regexp">/mirrors.aliyun.com/kubernetes</span><span class="regexp">/yum/doc</span><span class="regexp">/rpm-package-key.gpg</span></span><br><span class="line"><span class="regexp">EOF</span></span><br></pre></td></tr></table></figure><h3 id="安装kubelet、kubeadm、kubectl"><a href="#安装kubelet、kubeadm、kubectl" class="headerlink" title="安装kubelet、kubeadm、kubectl"></a>安装kubelet、kubeadm、kubectl</h3><a id="more"></a> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 禁用SELinux</span></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">'s/^SELINUX=enforcing$/SELINUX=permissive/'</span> /etc/selinux/config</span><br><span class="line">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br><span class="line">systemctl <span class="built_in">enable</span> --now kubelet</span><br></pre></td></tr></table></figure><h3 id="确保流量路由配置"><a href="#确保流量路由配置" class="headerlink" title="确保流量路由配置"></a>确保流量路由配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><h3 id="初始化kubeadm"><a href="#初始化kubeadm" class="headerlink" title="初始化kubeadm"></a>初始化kubeadm</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init --pod-network-cidr=192.168.0.0/16 --ignore-preflight-errors=Swap --upload-certs</span><br><span class="line"></span><br><span class="line">W0423 19:49:48.841139   10624 configset.go:202] WARNING: kubeadm cannot validate component configs <span class="keyword">for</span> API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class="line">[init] Using Kubernetes version: v1.18.2</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[WARNING IsDockerSystemdCheck]: detected <span class="string">"cgroupfs"</span> as the Docker cgroup driver. The recommended driver is <span class="string">"systemd"</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">[preflight] Pulling images required <span class="keyword">for</span> setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action <span class="keyword">in</span> beforehand using <span class="string">'kubeadm config images pull'</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[certs] Using certificateDir folder <span class="string">"/etc/kubernetes/pki"</span></span><br><span class="line">[certs] Generating <span class="string">"ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver"</span> certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed <span class="keyword">for</span> DNS names [izj6cbqyoktgsdsn8q6woqz kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 172.31.199.150]</span><br><span class="line">[certs] Generating <span class="string">"apiserver-kubelet-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"etcd/ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"etcd/server"</span> certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed <span class="keyword">for</span> DNS names [izj6cbqyoktgsdsn8q6woqz localhost] and IPs [172.31.199.150 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">"etcd/peer"</span> certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed <span class="keyword">for</span> DNS names [izj6cbqyoktgsdsn8q6woqz localhost] and IPs [172.31.199.150 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">"etcd/healthcheck-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver-etcd-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"sa"</span> key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder <span class="string">"/etc/kubernetes"</span></span><br><span class="line">[kubeconfig] Writing <span class="string">"admin.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"kubelet.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"controller-manager.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"scheduler.conf"</span> kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-apiserver"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-controller-manager"</span></span><br><span class="line">W0423 19:49:54.088376   10624 manifests.go:225] the default kube-apiserver authorization-mode is <span class="string">"Node,RBAC"</span>; using <span class="string">"Node,RBAC"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-scheduler"</span></span><br><span class="line">W0423 19:49:54.090110   10624 manifests.go:225] the default kube-apiserver authorization-mode is <span class="string">"Node,RBAC"</span>; using <span class="string">"Node,RBAC"</span></span><br><span class="line">[etcd] Creating static Pod manifest <span class="keyword">for</span> <span class="built_in">local</span> etcd <span class="keyword">in</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[<span class="built_in">wait</span>-control-plane] Waiting <span class="keyword">for</span> the kubelet to boot up the control plane as static Pods from directory <span class="string">"/etc/kubernetes/manifests"</span>. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 20.002596 seconds</span><br><span class="line">[upload-config] Storing the configuration used <span class="keyword">in</span> ConfigMap <span class="string">"kubeadm-config"</span> <span class="keyword">in</span> the <span class="string">"kube-system"</span> Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap <span class="string">"kubelet-config-1.18"</span> <span class="keyword">in</span> namespace kube-system with the configuration <span class="keyword">for</span> the kubelets <span class="keyword">in</span> the cluster</span><br><span class="line">[upload-certs] Storing the certificates <span class="keyword">in</span> Secret <span class="string">"kubeadm-certs"</span> <span class="keyword">in</span> the <span class="string">"kube-system"</span> Namespace</span><br><span class="line">[upload-certs] Using certificate key:</span><br><span class="line">c19b62a94f05d67b78200edba2e17e755e790606f19a935889714d32e73b663d</span><br><span class="line">[mark-control-plane] Marking the node izj6cbqyoktgsdsn8q6woqz as control-plane by adding the label <span class="string">"node-role.kubernetes.io/master=''"</span></span><br><span class="line">[mark-control-plane] Marking the node izj6cbqyoktgsdsn8q6woqz as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: hn5kpn.qkrhb88jauu9aglz</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class="keyword">in</span> order <span class="keyword">for</span> nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation <span class="keyword">for</span> all node client certificates <span class="keyword">in</span> the cluster</span><br><span class="line">[bootstrap-token] Creating the <span class="string">"cluster-info"</span> ConfigMap <span class="keyword">in</span> the <span class="string">"kube-public"</span> namespace</span><br><span class="line">[kubelet-finalize] Updating <span class="string">"/etc/kubernetes/kubelet.conf"</span> to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join 172.31.199.150:6443 --token hn5kpn.qkrhb88jauu9aglz \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:598ff568cd107d9ef9f780f86bd90051a0857da5197f5f8c19ed0dae8290366d</span><br></pre></td></tr></table></figure><p>请备份好 <code>kubeadm init</code> 输出中的 <code>kubeadm join</code> 命令，因为后面会需要这个命令来给集群添加节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 172.31.199.150:6443 --token hn5kpn.qkrhb88jauu9aglz \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:598ff568cd107d9ef9f780f86bd90051a0857da5197f5f8c19ed0dae8290366d</span><br></pre></td></tr></table></figure><h3 id="允许普通用户可以运行-kubectl"><a href="#允许普通用户可以运行-kubectl" class="headerlink" title="允许普通用户可以运行 kubectl"></a>允许普通用户可以运行 kubectl</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><h3 id="配置Calico网络"><a href="#配置Calico网络" class="headerlink" title="配置Calico网络"></a>配置Calico网络</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml</span><br></pre></td></tr></table></figure><h3 id="接下来将node节点加入集群"><a href="#接下来将node节点加入集群" class="headerlink" title="接下来将node节点加入集群"></a>接下来将node节点加入集群</h3><p>node节点同样上前面的流程安装docker、kubelet、kubeadm、kubectl。都安装完成后执行上面的<code>kubeadm join</code>命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join 172.31.199.150:6443 --token okdyiw.o8qjxl4v3avct79p \</span><br><span class="line">&gt;     --discovery-token-ca-cert-hash sha256:fb936d4c8da2dc276c6b447eea36d90bd9a206e1344c487418067faf580948e6 </span><br><span class="line"></span><br><span class="line">W0422 12:27:17.321756    2133 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not <span class="built_in">set</span>.</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[WARNING IsDockerSystemdCheck]: detected <span class="string">"cgroupfs"</span> as the Docker cgroup driver. The recommended driver is <span class="string">"systemd"</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with <span class="string">'kubectl -n kube-system get cm kubeadm-config -oyaml'</span></span><br><span class="line">[kubelet-start] Downloading configuration <span class="keyword">for</span> the kubelet from the <span class="string">"kubelet-config-1.18"</span> ConfigMap <span class="keyword">in</span> the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting <span class="keyword">for</span> the kubelet to perform the TLS Bootstrap...</span><br><span class="line"></span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"></span><br><span class="line">Run <span class="string">'kubectl get nodes'</span> on the control-plane to see this node join the cluster.</span><br></pre></td></tr></table></figure><p>然后在控制面板的机器上查看集群节点信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">NAME                      STATUS     ROLES    AGE    VERSION</span><br><span class="line">izj6cbqyoktgsdsn8q6woqz   Ready      master   55m    v1.18.2</span><br><span class="line">izj6cbwwgp62jm8oudjra8z   Ready      &lt;none&gt;   2m7s   v1.18.2</span><br><span class="line">izj6cbwwgp62jm8oudjra9z   NotReady   &lt;none&gt;   8s     v1.18.2</span><br></pre></td></tr></table></figure><p>至此，kubeadm集群节点安装成功</p><p>清理集群节点信息</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubeamd reset</span><br></pre></td></tr></table></figure><p>清理完成后记得执行下面的命令后重新配置config文件，不然会报错</p><blockquote><p>Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of “crypto/rsa: verification error” while trying to verify candidate authority certificate “kubernetes”)</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rm -rf <span class="variable">$HOME</span>/.kube</span><br><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p> <a href="https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/setup/production-environment/tools/kubeadm/install-kubeadm/</a> </p><p> <a href="https://kubernetes.io/zh/docs/setup/independent/create-cluster-kubeadm" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/setup/independent/create-cluster-kubeadm</a> </p><p> <a href="https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/reference/setup-tools/kubeadm/kubeadm/</a> </p><p> <a href="https://docs.projectcalico.org/getting-started/kubernetes/quickstart" target="_blank" rel="noopener">https://docs.projectcalico.org/getting-started/kubernetes/quickstart</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h2&gt;&lt;p&gt;kubeadm 搭建kubernetes集群环境&lt;/p&gt;
&lt;h2 id=&quot;准备条件&quot;&gt;&lt;a href=&quot;#准备条件&quot; class=&quot;headerlink&quot; title=&quot;准备条件&quot;&gt;&lt;/a&gt;准备条件&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;三台VPS（本文使用&lt;strong&gt;阿里云香港&lt;/strong&gt; - centos7.7）- 用国内的服务器折腾的好一会儿都被墙了，先不把时间浪费在这，直接上香港的服务器&lt;/li&gt;
&lt;li&gt;一台能SSH连接到VPS的本地电脑 （推荐连接工具xshell）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;安装步骤&quot;&gt;&lt;a href=&quot;#安装步骤&quot; class=&quot;headerlink&quot; title=&quot;安装步骤&quot;&gt;&lt;/a&gt;安装步骤&lt;/h2&gt;&lt;p&gt;在安装前需要配置国内的镜像源，这里推荐使用阿里云的&lt;/p&gt;
&lt;figure class=&quot;highlight crystal&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;cat &amp;lt;&amp;lt;EOF &amp;gt; &lt;span class=&quot;regexp&quot;&gt;/etc/yum&lt;/span&gt;.repos.d/kubernetes.repo&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[kubernetes]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;name=Kubernetes&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;baseurl=&lt;span class=&quot;symbol&quot;&gt;https:&lt;/span&gt;/&lt;span class=&quot;regexp&quot;&gt;/mirrors.aliyun.com/kubernetes&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/yum/repos&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/kubernetes-el7-x86_64/&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;enabled=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;gpgcheck=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;repo_gpgcheck=&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;gpgkey=&lt;span class=&quot;symbol&quot;&gt;https:&lt;/span&gt;/&lt;span class=&quot;regexp&quot;&gt;/mirrors.aliyun.com/kubernetes&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/yum/doc&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/yum-key.gpg https:/&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/mirrors.aliyun.com/kubernetes&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/yum/doc&lt;/span&gt;&lt;span class=&quot;regexp&quot;&gt;/rpm-package-key.gpg&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;regexp&quot;&gt;EOF&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h3 id=&quot;安装kubelet、kubeadm、kubectl&quot;&gt;&lt;a href=&quot;#安装kubelet、kubeadm、kubectl&quot; class=&quot;headerlink&quot; title=&quot;安装kubelet、kubeadm、kubectl&quot;&gt;&lt;/a&gt;安装kubelet、kubeadm、kubectl&lt;/h3&gt;
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://haoyunlaile.github.io/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="http://haoyunlaile.github.io/tags/kubernetes/"/>
    
      <category term="kubeadm" scheme="http://haoyunlaile.github.io/tags/kubeadm/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes dashboard install</title>
    <link href="http://haoyunlaile.github.io/2020/kubernates/kubernates-dashboard/"/>
    <id>http://haoyunlaile.github.io/2020/kubernates/kubernates-dashboard/</id>
    <published>2020-04-21T16:00:00.000Z</published>
    <updated>2020-04-21T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>基于网页查看Kubernetes 用户界面 </p><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>在控制面板节点部署dashborad</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure><h3 id="放开外网端口映射"><a href="#放开外网端口映射" class="headerlink" title="放开外网端口映射"></a>放开外网端口映射</h3><blockquote><p>如果需要外网访问，需要使用NodePort的方式对外暴露端口，不能使用<code>kubectl proxy</code>的方式，因为该方式只能通过http访问，非本地环境无法正常登录，在这里折腾了好几个小时，主要还是没有一字一句看官方文档。</p></blockquote><p>更改原文件<code>type: ClusterIP</code> 为<code>type: NodePort</code>后保存</p><a id="more"></a> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">kubectl</span> <span class="string">-n</span> <span class="string">kubernetes-dashboard</span> <span class="string">edit</span> <span class="string">service</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Please edit the object below. Lines beginning with a '#' will be ignored,</span></span><br><span class="line"><span class="comment"># and an empty file will abort the edit. If an error occurs while saving this file will be</span></span><br><span class="line"><span class="comment"># reopened with the relevant failures.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">resourceVersion:</span> <span class="string">"343478"</span></span><br><span class="line">  <span class="attr">selfLink:</span> <span class="string">/api/v1/namespaces/kubernetes-dashboard/services/kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">uid:</span> <span class="string">8e48f478-993d-11e7-87e0-901b0e532516</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">clusterIP:</span> <span class="number">10.100</span><span class="number">.124</span><span class="number">.90</span></span><br><span class="line">  <span class="attr">externalTrafficPolicy:</span> <span class="string">Cluster</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">  <span class="bullet">-</span> <span class="attr">port:</span> <span class="number">443</span></span><br><span class="line">    <span class="attr">protocol:</span> <span class="string">TCP</span></span><br><span class="line">    <span class="attr">targetPort:</span> <span class="number">8443</span></span><br><span class="line">  <span class="attr">selector:</span></span><br><span class="line">    <span class="attr">k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line">  <span class="attr">sessionAffinity:</span> <span class="string">None</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">ClusterIP</span></span><br><span class="line"><span class="attr">status:</span></span><br><span class="line">  <span class="attr">loadBalancer:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><h3 id="下一步获取nodeport对外开放的https端口，注意这里为32443端口"><a href="#下一步获取nodeport对外开放的https端口，注意这里为32443端口" class="headerlink" title="下一步获取nodeport对外开放的https端口，注意这里为32443端口"></a>下一步获取nodeport对外开放的https端口，注意这里为32443端口</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kubernetes-dashboard get service kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">NAME                   TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.98.33.83   &lt;none&gt;        443:32443/TCP   77m</span><br></pre></td></tr></table></figure><h3 id="同时启动监控指标收集服务，不然会dashborad无法展示数据图表"><a href="#同时启动监控指标收集服务，不然会dashborad无法展示数据图表" class="headerlink" title="同时启动监控指标收集服务，不然会dashborad无法展示数据图表"></a>同时启动监控指标收集服务，不然会dashborad无法展示数据图表</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.3.6/components.yaml</span><br></pre></td></tr></table></figure><p>然后就可以访问下面的地址</p><p><code>https://&lt;master-ip&gt;:&lt;nodePort&gt;</code></p><p>访问上面的地址会出现登录的界面，如下图：</p><p><img data-src="/images/k8s-dashboard-login.png" alt="k8s-dashboard-login"></p><p>这里选择使用token登录</p><p>创建dashboard对应的admin账户</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">touch dashboard-admin.yml</span><br><span class="line">vi dashboard-admin.yml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f dashboard-admin.yml</span><br></pre></td></tr></table></figure><p>然后通过如下命令获取登录的token</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk <span class="string">'&#123;print $1&#125;'</span>)</span><br><span class="line"></span><br><span class="line">Name:         admin-user-token-5j9gg</span><br><span class="line">Namespace:    kubernetes-dashboard</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: 8b1c0aa8-9ee1-4c06-a983-6cc8ebecf8b2</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  20 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6Im5BZWtISUdnVnloMDJiRjdLZ0pJdTMxNXZ2YTdtY2U2Z0p3QURlblFnSEEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLTVqOWdnIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbbWluLXVzZXIiLCJrddWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI4YjFjMGFhOC05ZWUxLTRjMDYtYTk4My02Y2M4ZWJlY2Y4YjIiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.C4Ma3tp6GdMCusjPEaQNqm_92-PEEm02-68OvsMq1eExPvMZxYYrvmwSWwOnJIps5mL2BEu1XqchsWlNFYpawe5HIk_zrimfff-NpwVRqxu0qPt0MxN0KzVgMm5hOaOYKYJW0zz1mpFZI8-uvqdDzwJGFan7vLH1KTCUt5gTHlv-KJyYa6zmE2QKl0-IATcesCF0sU51K2F5NeSU9dvE9hJ92mcETuGwXsuPo5aPSu-1yi1WFnaWDQrcJseXxOWREaYv0o-9swCZOYYBdNy7G4h6xB6cWxUD7C5Un4lB-5VaBqD0D_hS5Cwh3S5ETKYikag6-tB_sOdG7w-KuONicQ</span><br></pre></td></tr></table></figure><p>取上图的token字段粘贴进登录界面即可。</p><blockquote><p>注意，有的文章会写此方式获取到的token还需要进行base64解密，可能是因为版本原因，本人测试是可以直接复制后进行登录的</p></blockquote><p>登录成功后界面如图</p><p><img data-src="/images/k8s-dashboard-nodes.png" alt="k8s-dashboard-nodes.png"></p><p>终于装好了，踩了不少坑，主要还是不熟悉。后面切记认真仔细阅读官方文档。</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p> <a href="https://kubernetes.io/zh/docs/tasks/access-application-cluster/web-ui-dashboard/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/tasks/access-application-cluster/web-ui-dashboard/</a> </p><p> <a href="https://github.com/kubernetes/dashboard" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard</a> </p><p> <a href="https://github.com/kubernetes-sigs/metrics-server" target="_blank" rel="noopener">https://github.com/kubernetes-sigs/metrics-server</a></p><p> <a href="https://github.com/kubernetes/dashboard/blob/master/docs/user/accessing-dashboard/1.7.x-and-above.md" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard/blob/master/docs/user/accessing-dashboard/1.7.x-and-above.md</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h2&gt;&lt;p&gt;基于网页查看Kubernetes 用户界面 &lt;/p&gt;
&lt;h2 id=&quot;安装步骤&quot;&gt;&lt;a href=&quot;#安装步骤&quot; class=&quot;headerlink&quot; title=&quot;安装步骤&quot;&gt;&lt;/a&gt;安装步骤&lt;/h2&gt;&lt;p&gt;在控制面板节点部署dashborad&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h3 id=&quot;放开外网端口映射&quot;&gt;&lt;a href=&quot;#放开外网端口映射&quot; class=&quot;headerlink&quot; title=&quot;放开外网端口映射&quot;&gt;&lt;/a&gt;放开外网端口映射&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;如果需要外网访问，需要使用NodePort的方式对外暴露端口，不能使用&lt;code&gt;kubectl proxy&lt;/code&gt;的方式，因为该方式只能通过http访问，非本地环境无法正常登录，在这里折腾了好几个小时，主要还是没有一字一句看官方文档。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;更改原文件&lt;code&gt;type: ClusterIP&lt;/code&gt; 为&lt;code&gt;type: NodePort&lt;/code&gt;后保存&lt;/p&gt;
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://haoyunlaile.github.io/categories/kubernetes/"/>
    
    
      <category term="kubernetes-dashboard" scheme="http://haoyunlaile.github.io/tags/kubernetes-dashboard/"/>
    
  </entry>
  
  <entry>
    <title>centos7 install docker</title>
    <link href="http://haoyunlaile.github.io/2020/docker/docker-install/"/>
    <id>http://haoyunlaile.github.io/2020/docker/docker-install/</id>
    <published>2020-04-20T16:00:00.000Z</published>
    <updated>2020-04-20T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>安装docker运行环境</p><h2 id="准备条件"><a href="#准备条件" class="headerlink" title="准备条件"></a>准备条件</h2><ol><li>一台VPS（本文使用<strong>阿里云香港</strong> - centos7.7）</li><li>一台能SSH连接到VPS的本地电脑 （推荐连接工具xshell）</li></ol><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>安装docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com -o get-docker.sh</span><br><span class="line">sh get-docker.sh --mirror Aliyun</span><br></pre></td></tr></table></figure><p>配置docker访问加速</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tee /etc/docker/daemon.json &lt;&lt;-<span class="string">'EOF'</span></span><br><span class="line">&#123;</span><br><span class="line"> <span class="string">"registry-mirrors"</span>: [</span><br><span class="line">  <span class="string">"https://ze9vyrof.mirror.aliyuncs.com"</span>,</span><br><span class="line">     <span class="string">"https://registry.docker-cn.com"</span>,</span><br><span class="line">     <span class="string">"http://f1361db2.m.daocloud.io"</span>,</span><br><span class="line">     <span class="string">"https://docker.mirrors.ustc.edu.cn"</span></span><br><span class="line"> ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><a id="more"></a> <p>创建用户并加入docker组</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">useradd</span> <span class="string">-g docker docker</span></span><br><span class="line"><span class="attr">usermod</span> <span class="string">-aG docker docker</span></span><br></pre></td></tr></table></figure><p>加入开启启动、启动docker应用</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="keyword">enable</span> docker</span><br><span class="line">systemctl <span class="keyword">start</span> docker</span><br></pre></td></tr></table></figure><p>测试 Docker 是否安装正确</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">docker run hello-world</span><br><span class="line"></span><br><span class="line">Unable to find image <span class="string">'hello-world:latest'</span> locally</span><br><span class="line">latest: Pulling from library/hello-world</span><br><span class="line">0e03bdcc26d7: Pulling fs layer </span><br><span class="line">latest: Pulling from library/hello-world</span><br><span class="line">0e03bdcc26d7: Pull complete </span><br><span class="line">Digest: sha256:8e3114318a995a1ee497790535e7b88365222a21771ae7e53687ad76563e8e76</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> hello-world:latest</span><br><span class="line"></span><br><span class="line">Hello from Docker!</span><br><span class="line">This message shows that your installation appears to be working correctly.</span><br><span class="line"></span><br><span class="line">To generate this message, Docker took the following steps:</span><br><span class="line"> 1. The Docker client contacted the Docker daemon.</span><br><span class="line"> 2. The Docker daemon pulled the <span class="string">"hello-world"</span> image from the Docker Hub.</span><br><span class="line">    (amd64)</span><br><span class="line"> 3. The Docker daemon created a new container from that image <span class="built_in">which</span> runs the</span><br><span class="line">    executable that produces the output you are currently reading.</span><br><span class="line"> 4. The Docker daemon streamed that output to the Docker client, <span class="built_in">which</span> sent it</span><br><span class="line">    to your terminal.</span><br><span class="line"></span><br><span class="line">To try something more ambitious, you can run an Ubuntu container with:</span><br><span class="line"> $ docker run -it ubuntu bash</span><br><span class="line"></span><br><span class="line">Share images, automate workflows, and more with a free Docker ID:</span><br><span class="line"> https://hub.docker.com/</span><br><span class="line"></span><br><span class="line">For more examples and ideas, visit:</span><br><span class="line"> https://docs.docker.com/get-started/</span><br></pre></td></tr></table></figure><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p> <a href="https://docs.docker.com/engine/install/centos/" target="_blank" rel="noopener">https://docs.docker.com/engine/install/centos/</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h2&gt;&lt;p&gt;安装docker运行环境&lt;/p&gt;
&lt;h2 id=&quot;准备条件&quot;&gt;&lt;a href=&quot;#准备条件&quot; class=&quot;headerlink&quot; title=&quot;准备条件&quot;&gt;&lt;/a&gt;准备条件&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;一台VPS（本文使用&lt;strong&gt;阿里云香港&lt;/strong&gt; - centos7.7）&lt;/li&gt;
&lt;li&gt;一台能SSH连接到VPS的本地电脑 （推荐连接工具xshell）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;安装步骤&quot;&gt;&lt;a href=&quot;#安装步骤&quot; class=&quot;headerlink&quot; title=&quot;安装步骤&quot;&gt;&lt;/a&gt;安装步骤&lt;/h2&gt;&lt;p&gt;安装docker&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;curl -fsSL https://get.docker.com -o get-docker.sh&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sh get-docker.sh --mirror Aliyun&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;配置docker访问加速&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tee /etc/docker/daemon.json &amp;lt;&amp;lt;-&lt;span class=&quot;string&quot;&gt;&#39;EOF&#39;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; &lt;span class=&quot;string&quot;&gt;&quot;registry-mirrors&quot;&lt;/span&gt;: [&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; 	 &lt;span class=&quot;string&quot;&gt;&quot;https://ze9vyrof.mirror.aliyuncs.com&quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &lt;span class=&quot;string&quot;&gt;&quot;https://registry.docker-cn.com&quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &lt;span class=&quot;string&quot;&gt;&quot;http://f1361db2.m.daocloud.io&quot;&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;     &lt;span class=&quot;string&quot;&gt;&quot;https://docker.mirrors.ustc.edu.cn&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt; ]&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;EOF&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://haoyunlaile.github.io/categories/docker/"/>
    
    
      <category term="docker" scheme="http://haoyunlaile.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Minikube install</title>
    <link href="http://haoyunlaile.github.io/2020/kubernates/minikube-install/"/>
    <id>http://haoyunlaile.github.io/2020/kubernates/minikube-install/</id>
    <published>2020-04-20T16:00:00.000Z</published>
    <updated>2020-04-20T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>安装kubernetes - Minikube本地环境</p><h2 id="准备条件"><a href="#准备条件" class="headerlink" title="准备条件"></a>准备条件</h2><ol><li>一台VPS（本文使用<strong>阿里云香港</strong> - centos7.7）- 用国内的服务器折腾的好一会儿都被墙了，先不把时间浪费在这，直接上香港的服务器</li><li>一台能SSH连接到VPS的本地电脑 （推荐连接工具xshell）</li></ol><h2 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h2><p>在安装前需要配置国内的镜像源</p><a id="more"></a> <figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; <span class="regexp">/etc/yum</span>.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=<span class="symbol">https:</span>/<span class="regexp">/mirrors.aliyun.com/kubernetes</span><span class="regexp">/yum/repos</span><span class="regexp">/kubernetes-el7-x86_64/</span></span><br><span class="line">enabled=<span class="number">1</span></span><br><span class="line">gpgcheck=<span class="number">1</span></span><br><span class="line">repo_gpgcheck=<span class="number">1</span></span><br><span class="line">gpgkey=<span class="symbol">https:</span>/<span class="regexp">/mirrors.aliyun.com/kubernetes</span><span class="regexp">/yum/doc</span><span class="regexp">/yum-key.gpg https:/</span><span class="regexp">/mirrors.aliyun.com/kubernetes</span><span class="regexp">/yum/doc</span><span class="regexp">/rpm-package-key.gpg</span></span><br><span class="line"><span class="regexp">EOF</span></span><br></pre></td></tr></table></figure><h3 id="安装kubectl"><a href="#安装kubectl" class="headerlink" title="安装kubectl"></a>安装kubectl</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y kubectl</span><br></pre></td></tr></table></figure><p>  shell 中开启 kubectl 命令自动补全 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install bash-completion -y</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"source &lt;(kubectl completion bash)"</span> &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="安装minukube"><a href="#安装minukube" class="headerlink" title="安装minukube"></a>安装minukube</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 \</span><br><span class="line">  &amp;&amp; chmod +x minikube</span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">install minikube /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">su - docker</span><br></pre></td></tr></table></figure><h3 id="启动本地-Kubernetes-集群、-检查集群的状态"><a href="#启动本地-Kubernetes-集群、-检查集群的状态" class="headerlink" title="启动本地 Kubernetes 集群、 检查集群的状态"></a>启动本地 Kubernetes 集群、 检查集群的状态</h3><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">minikube start</span><br><span class="line"></span><br><span class="line">* minikube v1<span class="number">.9</span><span class="number">.2</span> on Centos <span class="number">7.7</span><span class="number">.1908</span></span><br><span class="line">* Automatically selected the docker driver</span><br><span class="line">* Starting control plane node m01 <span class="keyword">in</span> cluster minikube</span><br><span class="line">* Pulling base image ...</span><br><span class="line">* Downloading Kubernetes v1<span class="number">.18</span><span class="number">.0</span> preload ...</span><br><span class="line">    &gt; preloaded-images-k8s-v2-v1<span class="number">.18</span><span class="number">.0</span>-docker-overlay2-amd64.tar.lz4: <span class="number">542.91</span> MiB</span><br><span class="line">* Creating Kubernetes <span class="keyword">in</span> docker container with (CPUs=<span class="number">2</span>) (<span class="number">4</span> available), Memory=<span class="number">2200</span>MB (<span class="number">7821</span>MB available) ...</span><br><span class="line">* Preparing Kubernetes v1<span class="number">.18</span><span class="number">.0</span> on Docker <span class="number">19.03</span><span class="number">.2</span> ...</span><br><span class="line">  - kubeadm.pod-network-cidr=<span class="number">10.244</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">16</span></span><br><span class="line">* Enabling addons: <span class="keyword">default</span>-storageclass, storage-provisioner</span><br><span class="line">! Enabling <span class="string">'default-storageclass'</span> returned an error: running callbacks: [chmod: chmod deploy/addons/storageclass/storageclass.yaml.tmpl: permission denied]</span><br><span class="line">* Done! kubectl <span class="keyword">is</span> now configured to use <span class="string">"minikube"</span></span><br></pre></td></tr></table></figure><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">minikube</span> <span class="string">status</span></span><br><span class="line"></span><br><span class="line"><span class="attr">m01</span></span><br><span class="line"><span class="attr">host</span>: <span class="string">Running</span></span><br><span class="line"><span class="attr">kubelet</span>: <span class="string">Running</span></span><br><span class="line"><span class="attr">apiserver</span>: <span class="string">Running</span></span><br><span class="line"><span class="attr">kubeconfig</span>: <span class="string">Configured</span></span><br></pre></td></tr></table></figure><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="keyword">cluster</span>-<span class="keyword">info</span></span><br><span class="line"></span><br><span class="line">Kubernetes master <span class="keyword">is</span> running at https://<span class="number">172.17</span><span class="number">.0</span><span class="number">.2</span>:<span class="number">8443</span></span><br><span class="line">KubeDNS <span class="keyword">is</span> running at https://<span class="number">172.17</span><span class="number">.0</span><span class="number">.2</span>:<span class="number">8443</span>/api/v1/namespaces/kube-<span class="keyword">system</span>/services/kube-dns:dns/proxy</span><br><span class="line"></span><br><span class="line"><span class="keyword">To</span> further <span class="keyword">debug</span> <span class="keyword">and</span> diagnose <span class="keyword">cluster</span> problems, use <span class="string">'kubectl cluster-info dump'</span>.</span><br></pre></td></tr></table></figure><h3 id="开启Kubernetes-dashboard服务"><a href="#开启Kubernetes-dashboard服务" class="headerlink" title="开启Kubernetes dashboard服务"></a>开启Kubernetes dashboard服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">minikube dashboard --url</span><br><span class="line"></span><br><span class="line">* Enabling dashboard ...</span><br><span class="line">* Verifying dashboard health ...</span><br><span class="line">* Launching proxy ...</span><br><span class="line">* Verifying proxy health ...</span><br><span class="line">http://127.0.0.1:33457/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/</span><br></pre></td></tr></table></figure><h3 id="开启kube-proxy端口映射，使其可以远程访问"><a href="#开启kube-proxy端口映射，使其可以远程访问" class="headerlink" title="开启kube-proxy端口映射，使其可以远程访问"></a>开启kube-proxy端口映射，使其可以远程访问</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl<span class="built_in"> proxy </span><span class="attribute">--port</span>=33458 <span class="attribute">--address</span>=<span class="string">'0.0.0.0'</span> <span class="attribute">--accept-hosts</span>=<span class="string">'^.*'</span> &amp;</span><br></pre></td></tr></table></figure><p>这里需要记得去阿里云的安全组配置33458端口外网可以访问</p><p>然后就可以在浏览器访问k8s的dashborad了</p><p><a href="http://127.0.0.1:33458/" target="_blank" rel="noopener">http://127.0.0.1:33458/</a></p><p><img data-src="/images/k8s-dashboard.png" alt="k8s-dashboard"></p><p>清理 minikube 的本地状态 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">minikube delete</span><br></pre></td></tr></table></figure><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p> <a href="https://juejin.im/post/5b8a4536e51d4538c545645c" target="_blank" rel="noopener">https://juejin.im/post/5b8a4536e51d4538c545645c</a> </p><p> <a href="https://kubernetes.io/zh/docs/tasks/tools/install-minikube/" target="_blank" rel="noopener">https://kubernetes.io/zh/docs/tasks/tools/install-minikube/</a> </p><p> <a href="https://github.com/kubernetes/minikube" target="_blank" rel="noopener">https://github.com/kubernetes/minikube</a> </p><p> <a href="https://minikube.sigs.k8s.io/docs/handbook/dashboard/" target="_blank" rel="noopener">https://minikube.sigs.k8s.io/docs/handbook/dashboard/</a> </p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h2&gt;&lt;p&gt;安装kubernetes - Minikube本地环境&lt;/p&gt;
&lt;h2 id=&quot;准备条件&quot;&gt;&lt;a href=&quot;#准备条件&quot; class=&quot;headerlink&quot; title=&quot;准备条件&quot;&gt;&lt;/a&gt;准备条件&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;一台VPS（本文使用&lt;strong&gt;阿里云香港&lt;/strong&gt; - centos7.7）- 用国内的服务器折腾的好一会儿都被墙了，先不把时间浪费在这，直接上香港的服务器&lt;/li&gt;
&lt;li&gt;一台能SSH连接到VPS的本地电脑 （推荐连接工具xshell）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;安装步骤&quot;&gt;&lt;a href=&quot;#安装步骤&quot; class=&quot;headerlink&quot; title=&quot;安装步骤&quot;&gt;&lt;/a&gt;安装步骤&lt;/h2&gt;&lt;p&gt;在安装前需要配置国内的镜像源&lt;/p&gt;
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://haoyunlaile.github.io/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="http://haoyunlaile.github.io/tags/kubernetes/"/>
    
      <category term="minikube" scheme="http://haoyunlaile.github.io/tags/minikube/"/>
    
  </entry>
  
  <entry>
    <title>快速部署 Shadowsocks Docker版</title>
    <link href="http://haoyunlaile.github.io/2020/docker/docker-install-shadowsocks-libev/"/>
    <id>http://haoyunlaile.github.io/2020/docker/docker-install-shadowsocks-libev/</id>
    <published>2020-03-05T16:00:00.000Z</published>
    <updated>2020-03-05T16:00:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>搭梯子翻墙访问google</p><h2 id="准备条件"><a href="#准备条件" class="headerlink" title="准备条件"></a>准备条件</h2><ol><li>一台墙外VPS（本文使用腾讯云香港 - centos7.6）</li><li>一台能SSH连接到VPS的本地电脑 （推荐连接工具xshell）</li></ol><h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>因为在腾讯上直接安装使用shadowsocks遇到了”connect reset by peer”的问题，在公司访问(可直连境外)是正常的，用4g/家里wifi访问就会出现上述错误，怀疑是腾讯云做了相关网站的流量拦截，故想到这用docker再代理一层。</p><h2 id="服务端安装步骤"><a href="#服务端安装步骤" class="headerlink" title="服务端安装步骤"></a>服务端安装步骤</h2><p>安装docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -qO- get.docker.com | bash</span><br></pre></td></tr></table></figure><p>查看docker的版本信息、加入开启启动、启动docker应用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker version</span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure><p>拉取docker版shadowsocks-libev</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull appso/shadowsocks-libev</span><br></pre></td></tr></table></figure><p>创建shadowssocks配置文件，主要不要变动配置文件目录，默认配置路径为 <strong>/etc/shadowsocks-libev/config.json</strong></p>  <a id="more"></a> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/shadowsocks-libev/</span><br><span class="line">touch /etc/shadowsocks-libev/config.json</span><br><span class="line">vi /etc/shadowsocks-libev/config.json</span><br></pre></td></tr></table></figure><p>config.json 配置内容</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"server"</span>:<span class="string">"0.0.0.0"</span>,</span><br><span class="line">    <span class="attr">"server_port"</span>:<span class="number">443</span>,</span><br><span class="line">    <span class="attr">"password"</span>:<span class="string">"your client connection password"</span>,</span><br><span class="line">    <span class="attr">"timeout"</span>:<span class="number">300</span>,</span><br><span class="line">    <span class="attr">"method"</span>:<span class="string">"aes-256-gcm"</span>,</span><br><span class="line">    <span class="attr">"fast_open"</span>:<span class="literal">false</span>,</span><br><span class="line">    <span class="attr">"mode"</span>:<span class="string">"tcp_and_udp"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">名称</th><th align="center">解释</th></tr></thead><tbody><tr><td align="center">server</td><td align="center">服务端监听地址</td></tr><tr><td align="center">server_port</td><td align="center">客户端用于连接的端口</td></tr><tr><td align="center">password</td><td align="center">客户端用于连接的密码</td></tr><tr><td align="center">timeout</td><td align="center">超时时间</td></tr><tr><td align="center">method</td><td align="center">默认为 <code>aes-256-cfb</code>，参阅 <a href="https://github.com/shadowsocks/shadowsocks/wiki/Encryption" target="_blank" rel="noopener">Encryption</a></td></tr><tr><td align="center">mode</td><td align="center">是否启用 TCP / UDP 转发，参阅 <a href="https://jlk.fjfi.cvut.cz/arch/manpages/man/shadowsocks-libev.8" target="_blank" rel="noopener">shadowsocks-libev(8)</a></td></tr><tr><td align="center">fast_open</td><td align="center">是否启用 <a href="https://github.com/shadowsocks/shadowsocks/wiki/TCP-Fast-Open" target="_blank" rel="noopener">TCP Fast Open</a></td></tr></tbody></table><p>使用docker启动shadowsocks</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p 443:443 -p 443:443/udp --name ss-libev -v /etc/shadowsocks-libev:/etc/shadowsocks-libev appso/shadowsocks-libev</span><br></pre></td></tr></table></figure><p>查看容器启动状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@007_centos ~]<span class="comment"># docker ps -as</span></span><br><span class="line">CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS                  PORTS                                        NAMES               SIZE</span><br><span class="line">84c3fd45cbea        appso/shadowsocks-libev   <span class="string">"ss-server -c /etc/s…"</span>   2 days ago          Up 2 days               0.0.0.0:443-&gt;443/tcp, 0.0.0.0:443-&gt;443/udp    ss-libev           0B (virtual 120MB)</span><br></pre></td></tr></table></figure><p>查看端口(443)监听状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@007_centos ~]<span class="comment"># netstat -anp | grep 443</span></span><br><span class="line">tcp6       0      0 :::443                  :::*                    LISTEN      13435/docker-proxy  </span><br><span class="line">udp6       0      0 :::443                  :::*                                13446/docker-proxy</span><br></pre></td></tr></table></figure><p>至此，服务端安装完毕。</p><h2 id="windows客户端安装"><a href="#windows客户端安装" class="headerlink" title="windows客户端安装"></a>windows客户端安装</h2><p>打开 <a href="https://github.com/shadowsocks/shadowsocks-windows/releases" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-windows/releases</a> 下载最新版本客户端，截止本文编写时间，最新版本为 <a href="https://github.com/shadowsocks/shadowsocks-windows/releases/tag/4.1.9.2" target="_blank" rel="noopener">4.1.9.2</a> ，下载后直接打开对应客户端进行配置,应用确定即可。</p><p><img data-src="/images/shoadowsocks-windows.png" alt="shoadowsocks-windows"></p><p>如果使用chrome代理浏览器流量可以下载SwitchyOmega插件，直接安装到chrome的拓展程序里面即可</p><p>下载地址： <a href="https://github.com/FelisCatus/SwitchyOmega/releases" target="_blank" rel="noopener">https://github.com/FelisCatus/SwitchyOmega/releases</a> </p><p>插件配置如下</p><p><img data-src="/images/shoadowsocks-switchomega.png" alt="shoadowsocks-switchomega"></p><p>一般情况下，至此即可成功代理浏览器流量</p><h2 id="android客户端安装"><a href="#android客户端安装" class="headerlink" title="android客户端安装"></a>android客户端安装</h2><p>打开  <a href="https://github.com/shadowsocks/shadowsocks-android/releases" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-android/releases</a>  下载最新版本客户端，截止本文编写时间，最新版本为  <a href="https://github.com/shadowsocks/shadowsocks-android/releases/tag/v5.0.5" target="_blank" rel="noopener">v5.0.5</a>  ，下载后直接打开对应客户端进行配置,点击那个小飞机即可。</p><p>配置跟windows端配置类似，挺简单的，自行摸索一会儿就可以搞定。</p><p><img data-src="/images/shoadowsocks-android.png" alt="shoadowsocks-android"></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="https://github.com/shadowsocks/shadowsocks-libev" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-libev</a> </li><li><a href="https://github.com/shadowsocks/shadowsocks-android" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-android</a></li><li><a href="https://github.com/shadowsocks/shadowsocks-windows" target="_blank" rel="noopener">https://github.com/shadowsocks/shadowsocks-windows</a></li><li><a href="https://hub.docker.com/r/appso/shadowsocks-libev/" target="_blank" rel="noopener">https://hub.docker.com/r/appso/shadowsocks-libev/</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;需求&quot;&gt;&lt;a href=&quot;#需求&quot; class=&quot;headerlink&quot; title=&quot;需求&quot;&gt;&lt;/a&gt;需求&lt;/h2&gt;&lt;p&gt;搭梯子翻墙访问google&lt;/p&gt;
&lt;h2 id=&quot;准备条件&quot;&gt;&lt;a href=&quot;#准备条件&quot; class=&quot;headerlink&quot; title=&quot;准备条件&quot;&gt;&lt;/a&gt;准备条件&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;一台墙外VPS（本文使用腾讯云香港 - centos7.6）&lt;/li&gt;
&lt;li&gt;一台能SSH连接到VPS的本地电脑 （推荐连接工具xshell）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;遇到的问题&quot;&gt;&lt;a href=&quot;#遇到的问题&quot; class=&quot;headerlink&quot; title=&quot;遇到的问题&quot;&gt;&lt;/a&gt;遇到的问题&lt;/h2&gt;&lt;p&gt;因为在腾讯上直接安装使用shadowsocks遇到了”connect reset by peer”的问题，在公司访问(可直连境外)是正常的，用4g/家里wifi访问就会出现上述错误，怀疑是腾讯云做了相关网站的流量拦截，故想到这用docker再代理一层。&lt;/p&gt;
&lt;h2 id=&quot;服务端安装步骤&quot;&gt;&lt;a href=&quot;#服务端安装步骤&quot; class=&quot;headerlink&quot; title=&quot;服务端安装步骤&quot;&gt;&lt;/a&gt;服务端安装步骤&lt;/h2&gt;&lt;p&gt;安装docker&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;wget -qO- get.docker.com | bash&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;查看docker的版本信息、加入开启启动、启动docker应用&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;docker version&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;systemctl &lt;span class=&quot;built_in&quot;&gt;enable&lt;/span&gt; docker&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;systemctl start docker&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;拉取docker版shadowsocks-libev&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;docker pull appso/shadowsocks-libev&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;创建shadowssocks配置文件，主要不要变动配置文件目录，默认配置路径为 &lt;strong&gt;/etc/shadowsocks-libev/config.json&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="docker" scheme="http://haoyunlaile.github.io/categories/docker/"/>
    
    
      <category term="shadowsocks" scheme="http://haoyunlaile.github.io/tags/shadowsocks/"/>
    
      <category term="docker" scheme="http://haoyunlaile.github.io/tags/docker/"/>
    
  </entry>
  
</feed>
